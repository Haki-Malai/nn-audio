{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python363jvsc74a57bd04c622b718bf9e061ea1a692dd46a8bb5928d3145b3a402924c30e011fa7f6cdc",
   "display_name": "Python 3.6.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "4c622b718bf9e061ea1a692dd46a8bb5928d3145b3a402924c30e011fa7f6cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#Loading Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydub\n",
    "import os\n",
    "import re\n",
    "from scipy.io.wavfile import read, write"
   ]
  },
  {
   "source": [
    "#Loading the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#training dataset\n",
    "train_path  = '../dataset/wavLITE/train/'\n",
    "errors = []\n",
    "complete = 0\n",
    "dataset = []\n",
    "for filename in os.listdir(train_path):\n",
    "    try:\n",
    "        fs, y = read(train_path+'true/'+filename)\n",
    "        dataset = np.array([y,1])\n",
    "        complete = complete + 1\n",
    "    else:\n",
    "        errors = errors.append(filename)\n",
    "    print('Complete: ',(complete*100)/len(os.listdir(train_path)),'%')\n",
    "\n",
    "complete = 0\n",
    "for filename in os.listdir(train_path):\n",
    "    try:\n",
    "        fs, y = read(train_path+'false/'+filename)\n",
    "        dataset = np.array([y,0])\n",
    "        complete = complete + 1\n",
    "    else:\n",
    "        errors = errors.append(filename)\n",
    "    print('Complete: ',(complete*100)/len(os.listdir(train_path)),'%')\n",
    "\n",
    "print(\"Script complete with \", len(errors), \" errors.\")\n",
    "if len(errors):\n",
    "    for error in errors:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset\n",
    "test_data = []\n",
    "test_path  = '../dataset/wavLITE/test/'\n",
    "for filename in os.listdir(test_path):\n",
    "    try:\n",
    "        fs, y = read(test_path+'true/'+filename)\n",
    "        dataset = np.array([y,1])\n",
    "        complete = complete + 1\n",
    "    else:\n",
    "        errors = errors.append(filename)\n",
    "    print('Complete: ',(complete*100)/len(os.listdir(test_path)),'%')\n",
    "\n",
    "complete = 0\n",
    "for filename in os.listdir(test_path):\n",
    "    try:\n",
    "        fs, y = read(test_path+'false/'+filename)\n",
    "        dataset = np.array([y,0])\n",
    "        complete = complete + 1\n",
    "    else:\n",
    "        errors = errors.append(filename)\n",
    "    print('Complete: ',(complete*100)/len(os.listdir(test_path)),'%')\n",
    "\n",
    "print(\"Script complete with \", len(errors), \" errors.\")\n",
    "if len(errors):\n",
    "    for error in errors:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataset list of numpy arrays to list of tensors\n",
    "for data in dataset:    \n",
    "    tf.convert_to_tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('original.wav', 44100, y)"
   ]
  }
 ]
}